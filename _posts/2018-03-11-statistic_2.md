---
layout: post
title: "Probability & Distribution (2)"
description: "The Probability Set Function"
date: 2018-03-11
tags: [statistic, mathematical statistics, study]
comments: true
---



## 1.3 The Probability Set Function

#### Definition 1.3.1

$$\sigma-field$$.

- Let $$\beta$$ be a collection of subset of $$\mathscr{C}$$[^1].

  We say $$\beta$$ is a **$$\sigma-field$$**,

- if 

  1. $$\emptyset \notin \beta$$.
  2. $$C\in \beta \Rightarrow C^c\in \beta$$. (cloed under complement)
  3. $$C_1, C_2\cdots\in\beta\Rightarrow\bigcup_{i=1}^{\infty}$$. (closed under countable union)

#### Definition 1.3.2 

$$Probability$$.

- $$\mathscr{C}$$ : Sample Space.
- $$\beta$$ : Borel $$\sigma-field$$.
- P : Real-valued function defined on $$\beta$$
  Probability set function if it satisfied,
  1. $$P\left(c\right)\ge0, \quad \forall C\in\beta\quad$$  **(Non Negative)**
  2. $$P\left(e\right)=1,\quad$$           **(Normality)**
  3. $$C_1, C_2, \cdots\in\beta, \quad C_m\cap C_n = \emptyset,\quad \forall m\neq n$$
     $$\Rightarrow P\left(\bigcup_{i=1}^{\infty}C_i\right) = \sum_{i=1}^{\infty}P\left(i\right),\quad$$**(Countable additivity)**

##### Theorem 1.3.1

$$
\begin{aligned}
	P\left(c\right) = 1-P\left(C^c\right), \quad \forall C\in\beta
\end{aligned}
$$

- Proof.
  - $$\mathscr{C} = C\cup C^c$$.
  - $$P\left(\mathscr{C}\right)= P\left(C\right) + P\left(C^c\right)\quad \left(\because\text{Countable Addictivity}\right)$$.
  - $$P\left(\mathscr{C}\right) = 1\qquad\qquad\qquad\quad \left(\because Normality\right)$$.

##### Theorem 1.3.2

$$
\begin{aligned}
	P\left(\phi\right) = 0
\end{aligned}
$$

- Proof.
  - $$\mathscr{C}= \mathscr{C}\cup\emptyset$$.
  - $$P\left(\mathscr{C}\right) = P\left(\mathscr{C}\right) + P\left(\emptyset\right)$$.

##### Theorem 1.3.3

$$
C_1\subset C_2 \Rightarrow P\left(C_1\right)\le P\left(C_2\right)
$$

- Proof.
  - $$C_2 = C_1\cup\left(C_2\cap C_1^c\right)$$.
  - $$\phi\ \ = C_1\cap \left(C_1^c\cap C_2\right)$$.
  - $$P\left(C_2\right)=P\left(C_1\right)+P\left(C_2\cap C_1^c\right)$$.

##### Theorem 1.3.4

$$
0\le P\left(C\right) \le 1, \quad \forall C \le \beta
$$

- Proof.
  - $$\phi \subset C \subset \mathscr{C}$$.
  - $$0 = P\left(\phi\right) \le P\left(C\right) \le P\left(\mathscr{C}\right) = 1$$.

##### Theorem 1.3.5

$$
\begin{aligned}
	P\left(C_1\cup C_2\right) = & P\left(C_1\right) + P\left(C_2\right) - P\left(C_1\cap C_2\right)
\end{aligned}
$$

- Proof.

$$
\begin{aligned}
	\quad C_1 \cup C_2 = &\ C_1 \cup \left(C_2 \cap C_1^c\right) \\
	\quad C_2 = &\ \left(C_1 \cap C_2\right) \cup \left(C_2 \cap C_1^c\right) \\
	\quad P\left(C_1 \cup C_2\right) = &\ P\left(C_1\right) + P\left(C_2 \cap C_1^c\right) \\
	\quad P\left(C_2\right) = & \ P\left(C_1 \cap C_2\right) + P\left(C_2\cap C_1^c\right)
\end{aligned}
$$







#### Remark 1.3.2

$$\left(\text{Inclusion Exclusion Formula}\right)$$

- For 3 sets $$C_1, C_2, C_3$$ it is not difficult to show.
  $$
  \begin{aligned}
  	P\left(C_1\cup C_2 \cup C_3\right) = & \ p_1 - p_2 + p_3\\
  	\text{where}, \quad p_1 =&\ P\left(C_1\right) + P\left(C_2\right) + P\left(C_3\right)\\
  	p_2 =&\ P\left(C_1\cap C_2\right) + P\left(C_1\cap C_3\right) + P\left(C_2 \cap C_3\right)\\
  	p_3 =&\ P\left(C_1\cap C_2 \cap C_3\right)\\
  \end{aligned}
  $$
  ​

- In general **inclusion exclusion formula**,
  $$
  P\left(C_1\cup C_2 \cdots \cup C_k\right) = \ p_1 - p_2 + p+3 - \cdots + \left(-1\right)^{k+1}p_k,
  $$
  ​

- where $$p_i$$ is sum of probability of all possible intersection of sets. 
  $$C_1, C_2, \cdots$$ are called mutually exclusion.

- If $$C_i \cap C_j = \phi,\quad \forall i \neq j$$, mutually exclusive set $$c_1, c_2, \cdots$$ are called **exhaustive**[^2]. $$\left(\bigcup_{i=1}^{\infty}C_i\right)$$

------

[^1]: Sample Space
[^2]: partition

